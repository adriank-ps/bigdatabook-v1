#!/bin/bash
#usage: source prepare_env

export SPARK_HOME='/home/halamix2/studia/big_data/spark_download/spark-3.0.0-preview2-bin-hadoop3.2'
export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH

export PYSPARK_PYTHON=python3

# you can replace jupyter with python3 and left PYSPARK_DRIVER_PYTHON_OPTS empty if you don't want to use Jupyter
export PYSPARK_DRIVER_PYTHON="jupyter"
export PYSPARK_DRIVER_PYTHON_OPTS="notebook"

echo "env. variables for pySpark are set"
